{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading from S3 and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# --- Download from S3 ---\n",
    "bucket = \"hqpsusu-ml-data-bucket\"\n",
    "prefix = \"final_project/models/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "local_rf  = \"/tmp/rf_model.pkl\"\n",
    "local_xgb = \"/tmp/xgb_model.pkl\"\n",
    "\n",
    "s3.download_file(bucket, prefix + \"rf_model.pkl\", local_rf)\n",
    "s3.download_file(bucket, prefix + \"xgb_model.pkl\", local_xgb)\n",
    "\n",
    "# --- Load models ---\n",
    "rf_loaded  = joblib.load(local_rf)\n",
    "xgb_loaded = joblib.load(local_xgb)\n",
    "\n",
    "\n",
    "# Optional: LSTM\n",
    "try:\n",
    "    import torch\n",
    "    lstm_loaded = mlflow.pytorch.load_model(lstm_uri)\n",
    "    has_lstm = True\n",
    "except Exception:\n",
    "    print(\"ℹ️ No LSTM found in S3 — skipping.\")\n",
    "    has_lstm = False\n",
    "\n",
    "# =========================================================\n",
    "# 3) Evaluation helper\n",
    "# =========================================================\n",
    "def eval_model(name, y_true, y_pred):\n",
    "    eps = 1e-6\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    yt, yp = np.asarray(y_true)[mask], np.asarray(y_pred)[mask]\n",
    "    errors = yp - yt\n",
    "    abs_err = np.abs(errors)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"MAE\": mean_absolute_error(yt, yp),\n",
    "        \"RMSE\": mean_squared_error(yt, yp, squared=False),\n",
    "        \"Bias\": np.mean(errors),\n",
    "        \"sMAPE (%)\": 100.0 * np.mean(2.0 * abs_err / (np.abs(yt) + np.abs(yp) + eps)),\n",
    "        \"≤5 min\": 100.0 * np.mean(abs_err <= 5),\n",
    "        \"≤10 min\": 100.0 * np.mean(abs_err <= 10),\n",
    "        \"R²\": r2_score(yt, yp),\n",
    "        \"Errors\": errors,\n",
    "        \"y_true\": yt,\n",
    "        \"y_pred\": yp\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# 4) Run predictions\n",
    "# =========================================================\n",
    "results = []\n",
    "\n",
    "# RF\n",
    "y_pred_rf = rf_loaded.predict(X_test)\n",
    "results.append(eval_model(\"RandomForest (S3)\", y_test, y_pred_rf))\n",
    "\n",
    "# XGB\n",
    "y_pred_xgb = xgb_loaded.predict(X_test)\n",
    "results.append(eval_model(\"XGBoost (S3)\", y_test, y_pred_xgb))\n",
    "\n",
    "# LSTM\n",
    "if has_lstm:\n",
    "    y_pred_lstm = lstm_loaded(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy().ravel()\n",
    "    results.append(eval_model(\"LSTM (S3)\", y_test, y_pred_lstm))\n",
    "\n",
    "# =========================================================\n",
    "# 5) Tabulate results\n",
    "# =========================================================\n",
    "df_results = pd.DataFrame(results).drop(columns=[\"Errors\",\"y_true\",\"y_pred\"])\n",
    "print(df_results)\n",
    "\n",
    "# =========================================================\n",
    "# 6) Visuals\n",
    "# =========================================================\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "# (A) Predicted vs Actual\n",
    "for i, res in enumerate(results, 1):\n",
    "    yt, yp = res[\"y_true\"], res[\"y_pred\"]\n",
    "    ax = plt.subplot(1, len(results), i)\n",
    "    ax.scatter(yt, yp, s=10, alpha=0.5)\n",
    "    mn, mx = yt.min(), yt.max()\n",
    "    ax.plot([mn, mx], [mn, mx], \"r--\")\n",
    "    ax.set_title(f\"{res['Model']}\\nMAE={res['MAE']:.2f}, RMSE={res['RMSE']:.2f}, R²={res['R²']:.2f}\")\n",
    "    ax.set_xlabel(\"Actual RUL\")\n",
    "    ax.set_ylabel(\"Predicted RUL\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (B) Error distributions\n",
    "plt.figure(figsize=(10,6))\n",
    "for res in results:\n",
    "    plt.hist(res[\"Errors\"], bins=60, alpha=0.5, label=res[\"Model\"])\n",
    "plt.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"Prediction Error (min)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Error Distributions\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
