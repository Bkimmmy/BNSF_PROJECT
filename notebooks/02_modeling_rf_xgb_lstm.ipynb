{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Feature Distributions by Failure Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert Spark DataFrame → Pandas for visualization\n",
    "# (sample 10% of the dataset to avoid memory issues on large data)\n",
    "pdf = features_with_failure.select(\n",
    "    \"Motor_current_avg\", \n",
    "    \"Oil_temp_avg\", \n",
    "    \"DV_pressure_avg\", \n",
    "    \"failure\"\n",
    ").sample(fraction=0.1, seed=42).toPandas()\n",
    "\n",
    "# Plot distributions of key features, split by failure vs. non-failure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, col in zip(axes, [\"Motor_current_avg\", \"Oil_temp_avg\", \"DV_pressure_avg\"]):\n",
    "    # Histogram for normal operation\n",
    "    pdf[pdf[\"failure\"]==0][col].hist(ax=ax, bins=50, alpha=0.5, label=\"No Failure\")\n",
    "    # Histogram for failure cases\n",
    "    pdf[pdf[\"failure\"]==1][col].hist(ax=ax, bins=50, alpha=0.5, label=\"Failure\")\n",
    "    ax.set_title(f\"{col} distribution\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Boxplots of Features by Failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Boxplots to visualize feature distributions grouped by failure vs. non-failure.\n",
    "# Complements histograms by showing median, quartiles, and outliers.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for ax, col in zip(axes, [\"Motor_current_avg\", \"Oil_temp_avg\", \"DV_pressure_avg\"]):\n",
    "    sns.boxplot(x=\"failure\", y=col, data=pdf, ax=ax)\n",
    "    ax.set_title(f\"{col} by failure\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Sensor Trends Around Failures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Select a few distinct failure events (timestamps)\n",
    "failure_times = (\n",
    "    features_with_failure\n",
    "    .filter(features_with_failure.failure == 1)\n",
    "    .select(\"timestamp_hour\")\n",
    "    .distinct()\n",
    "    .limit(3)  # sample 3 failures to visualize\n",
    "    .toPandas()[\"timestamp_hour\"]\n",
    ")\n",
    "\n",
    "# 2. Convert Spark DataFrame → Pandas for time series visualization\n",
    "pdf = features_with_failure.toPandas()\n",
    "\n",
    "# 3. Normalize signals (z-score) for comparability across features\n",
    "for col in [\"Motor_current_avg\", \"Oil_temp_avg\", \"DV_pressure_avg\"]:\n",
    "    pdf[col + \"_norm\"] = (pdf[col] - pdf[col].mean()) / pdf[col].std()\n",
    "\n",
    "# 4. Plot trends around each sampled failure event\n",
    "for ft in failure_times:\n",
    "    # Create a 24-hour window centered around the failure (±12h)\n",
    "    window = pdf[\n",
    "        (pdf[\"timestamp_hour\"] >= ft - pd.Timedelta(hours=12)) &\n",
    "        (pdf[\"timestamp_hour\"] <= ft + pd.Timedelta(hours=12))\n",
    "    ]\n",
    "    \n",
    "    # Aggregate to hourly means (reduce noise in high-frequency signals)\n",
    "    window_grouped = (\n",
    "        window.groupby(\"timestamp_hour\")[[\n",
    "            \"Motor_current_avg_norm\", \n",
    "            \"Oil_temp_avg_norm\", \n",
    "            \"DV_pressure_avg_norm\"\n",
    "        ]].mean().reset_index()\n",
    "    )\n",
    "    \n",
    "    # Time series plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(window_grouped[\"timestamp_hour\"], window_grouped[\"Motor_current_avg_norm\"], \n",
    "             label=\"Motor Current (norm)\", color=\"blue\")\n",
    "    plt.plot(window_grouped[\"timestamp_hour\"], window_grouped[\"Oil_temp_avg_norm\"], \n",
    "             label=\"Oil Temp (norm)\", color=\"orange\")\n",
    "    plt.plot(window_grouped[\"timestamp_hour\"], window_grouped[\"DV_pressure_avg_norm\"], \n",
    "             label=\"DV Pressure (norm)\", color=\"green\")\n",
    "    \n",
    "    # Mark the failure event\n",
    "    plt.axvline(ft, color=\"red\", linestyle=\"--\", label=\"Failure Event\")\n",
    "    plt.title(f\"Normalized Sensor Trends Around Failure at {ft}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Normalized Sensor Values (z-score)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Aggregated Trends Leading to Failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Convert Spark DataFrame → Pandas for plotting\n",
    "pdf = features_with_failure.toPandas()\n",
    "pdf['timestamp_hour'] = pd.to_datetime(pdf['timestamp_hour'])\n",
    "\n",
    "# 2. Identify failure event timestamps\n",
    "failure_times = pdf[pdf['failure'] == 1]['timestamp_hour']\n",
    "\n",
    "# 3. Collect pre-failure windows (12h before each failure)\n",
    "records = []\n",
    "window = 12  # hours lookback\n",
    "\n",
    "for ft in failure_times:\n",
    "    subset = pdf[\n",
    "        (pdf['timestamp_hour'] >= ft - pd.Timedelta(hours=window)) &\n",
    "        (pdf['timestamp_hour'] <= ft)\n",
    "    ].copy()\n",
    "    # Add relative time axis (\"hours to failure\")\n",
    "    subset['hours_to_failure'] = (subset['timestamp_hour'] - ft).dt.total_seconds() / 3600\n",
    "    records.append(subset)\n",
    "\n",
    "# 4. Combine all pre-failure windows into one aligned dataset\n",
    "aligned = pd.concat(records)\n",
    "\n",
    "# 5. Aggregate mean + std for sensor values across failures\n",
    "agg = (\n",
    "    aligned\n",
    "    .groupby('hours_to_failure')[['Motor_current_avg','Oil_temp_avg','DV_pressure_avg']]\n",
    "    .agg(['mean','std'])\n",
    ")\n",
    "\n",
    "# 6. Normalize (z-score across time) for comparability\n",
    "norm = (agg - agg.mean()) / agg.std()\n",
    "\n",
    "# 7. Plot aggregated normalized trends with ±1 std shading\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for sensor, color in zip(['Motor_current_avg','Oil_temp_avg','DV_pressure_avg'],\n",
    "                         ['blue','orange','green']):\n",
    "    mean = norm[sensor]['mean']\n",
    "    std = norm[sensor]['std']\n",
    "    plt.plot(mean.index, mean.values, label=f\"{sensor} (norm)\", color=color)\n",
    "    plt.fill_between(mean.index, mean-std, mean+std, color=color, alpha=0.2)\n",
    "\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Failure Event\")\n",
    "plt.title(\"Normalized Sensor Trends Before Failure (Mean ± Std)\")\n",
    "plt.xlabel(\"Hours to Failure\")\n",
    "plt.ylabel(\"Normalized Sensor Values (z-score)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Feature Distributions & Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3: EDA (Part 2: Distributions + Correlations) ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Convert Spark DataFrame → Pandas for plotting\n",
    "pdf = df_final.toPandas()\n",
    "\n",
    "# 2. Identify numeric columns (ignore categorical / string cols)\n",
    "num_cols = [c for c in pdf.columns if pd.api.types.is_numeric_dtype(pdf[c])]\n",
    "\n",
    "# --- Histograms for numeric sensor features ---\n",
    "# Shows distributions (shape, skew, outliers) for first 12 numeric columns\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, col in enumerate(num_cols[:12]):  # limit to 12 for readability\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    sns.histplot(pdf[col].dropna(), bins=40, kde=True, color=\"steelblue\")\n",
    "    plt.title(col, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "plt.suptitle(\"Sensor Distributions (sampled)\", fontsize=14, weight=\"bold\")\n",
    "plt.show()\n",
    "\n",
    "# --- Correlation heatmap ---\n",
    "# Highlights relationships between engineered features\n",
    "# Useful for detecting multicollinearity and redundant features\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = pdf[num_cols].corr()\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0, annot=False, cbar=True)\n",
    "plt.title(\"Correlation Heatmap of Engineered Features\", fontsize=14, weight=\"bold\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis – Correlations & Boxplots of Key Sensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Convert Spark → Pandas for easier plotting\n",
    "pdf = df_final.toPandas()\n",
    "\n",
    "# 2. Filter numeric columns only\n",
    "num_cols = [c for c in pdf.columns if pd.api.types.is_numeric_dtype(pdf[c])]\n",
    "pdf_num = pdf[num_cols].dropna()\n",
    "\n",
    "# -----------------------------\n",
    "# Correlation Heatmap\n",
    "# -----------------------------\n",
    "# Shows linear relationships between numeric features\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = pdf_num.corr()\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(\"Sensor Correlation Heatmap\", fontsize=16, weight=\"bold\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Boxplots for Key Sensor Signals\n",
    "# -----------------------------\n",
    "# Compares distributions + outliers for a selected subset of features\n",
    "sample_sensors = [\n",
    "    \"Motor_current_avg\",\n",
    "    \"Oil_temperature_avg\",\n",
    "    \"DV_pressure_avg\",\n",
    "    \"gpsSpeed_avg\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "pdf_melt = pdf[sample_sensors].melt(var_name=\"Sensor\", value_name=\"Value\")\n",
    "sns.boxplot(x=\"Sensor\", y=\"Value\", data=pdf_melt)\n",
    "plt.title(\"Boxplots of Key Sensor Signals\", fontsize=16, weight=\"bold\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dimensions Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Rows and columns before dropping non-feature columns\n",
    "print(\"Full dataset shape:\", pdf.shape)\n",
    "\n",
    "# Rows and columns actually used for modeling (X only)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "\n",
    "# Target vector length\n",
    "print(\"Target vector length:\", y.shape)\n",
    "\n",
    "# Raw data dimensions\n",
    "print(\"Raw row count:\", iot_df.count())\n",
    "print(\"Raw column count:\", len(iot_df.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation (RandomForest, XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Libraries & Setup\n",
    "# =========================================================\n",
    "# Core data handling & visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning models & metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ensure consistent plotting style\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# Backwards-compatible RMSE function for sklearn\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error as rmse_fn\n",
    "except Exception:\n",
    "    def rmse_fn(y_true, y_pred):\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Prepare Training Data\n",
    "# =========================================================\n",
    "# Keep only rows with valid Remaining Useful Life (RUL) labels\n",
    "train_df = df_final.filter(df_final[\"RUL_minutes\"].isNotNull())\n",
    "pdf = train_df.toPandas()\n",
    "\n",
    "# (Optional) Add cyclic features for time-of-day\n",
    "if \"timestamp_bin\" in pdf.columns:\n",
    "    tod_min = pdf[\"timestamp_bin\"].dt.hour * 60 + pdf[\"timestamp_bin\"].dt.minute\n",
    "    pdf[\"tod_sin\"] = np.sin(2 * np.pi * tod_min / 1440.0)\n",
    "    pdf[\"tod_cos\"] = np.cos(2 * np.pi * tod_min / 1440.0)\n",
    "\n",
    "# Define target variable and drop metadata columns\n",
    "drop_cols = [\n",
    "    \"timestamp_bin\", \n",
    "    \"failure\", \n",
    "    \"next_failure_time\", \n",
    "    \"last_failure_time\", \n",
    "    \"minutes_since_last_failure\", \n",
    "    \"RUL_minutes\"\n",
    "]\n",
    "y = pdf[\"RUL_minutes\"]\n",
    "num_cols = [c for c in pdf.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(pdf[c])]\n",
    "X = pdf[num_cols].copy()\n",
    "\n",
    "# Train/test split without shuffling (time-ordered)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Handle NaNs/infs by replacing with training medians\n",
    "train_medians = X_train.median(numeric_only=True)\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(train_medians)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan).fillna(train_medians)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}  |  Train: {X_train.shape}  Test: {X_test.shape}\")\n",
    "print(f\"Target length: {y.shape}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Train Models\n",
    "# =========================================================\n",
    "# Random Forest Regressor (simplified config for speed)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# XGBoost Regressor (faster training config)\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) Evaluate Models\n",
    "# =========================================================\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    \"\"\"Compute MAE and RMSE for a given model’s predictions\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = rmse_fn(y_true, y_pred)\n",
    "    print(f\"{name:12s} → MAE: {mae:.3f} | RMSE: {rmse:.3f}\")\n",
    "    return mae, rmse\n",
    "\n",
    "mae_rf,  rmse_rf  = evaluate(\"RandomForest\", y_test, y_pred_rf)\n",
    "mae_xgb, rmse_xgb = evaluate(\"XGBoost\",      y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4) Visualizations\n",
    "# =========================================================\n",
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "# (a) Predicted vs Actual\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.4, label=\"RF\")\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.4, label=\"XGB\")\n",
    "mn, mx = float(y_test.min()), float(y_test.max())\n",
    "plt.plot([mn, mx], [mn, mx], \"k--\", linewidth=1)\n",
    "plt.xlabel(\"Actual RUL (min)\")\n",
    "plt.ylabel(\"Predicted RUL (min)\")\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.legend()\n",
    "\n",
    "# (b) Error Distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(y_pred_rf - y_test, bins=40, alpha=0.6, label=\"RF\")\n",
    "plt.hist(y_pred_xgb - y_test, bins=40, alpha=0.6, label=\"XGB\")\n",
    "plt.xlabel(\"Prediction Error (min)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Error Distribution\")\n",
    "plt.legend()\n",
    "\n",
    "# (c) Feature Importance (Top 15, XGBoost)\n",
    "plt.subplot(1, 3, 3)\n",
    "imp = pd.Series(xgb_model.feature_importances_, index=X_train.columns)\n",
    "topk = imp.sort_values(ascending=False).head(15)[::-1]\n",
    "plt.barh(topk.index, topk.values)\n",
    "plt.title(\"XGBoost Feature Importance (Top 15)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top contributing features\n",
    "rf_imp = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(20)\n",
    "xgb_imp = imp.sort_values(ascending=False).head(20)\n",
    "\n",
    "print(\"\\nTop 20 features (RF):\")\n",
    "print(rf_imp)\n",
    "\n",
    "print(\"\\nTop 20 features (XGB):\")\n",
    "print(xgb_imp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Modeling: Sequence Approach (Aligned with RF/XGB Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Make LSTM use the exact same split as RF/XGB and add it to comparison ----\n",
    "import numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1) Reconstruct the full, already-imputed matrix & target\n",
    "X_full = np.vstack([np.asarray(X_train), np.asarray(X_test)])\n",
    "y_full = np.concatenate([np.asarray(y_train), np.asarray(y_test)])\n",
    "cut    = len(y_train)                      # same cutoff as RF/XGB\n",
    "SEQ_LEN = 30\n",
    "\n",
    "# 2) Build rolling sequences whose TARGET index aligns with the same cutoff\n",
    "Xs, ys, tgt = [], [], []\n",
    "for i in range(len(X_full) - SEQ_LEN):\n",
    "    Xs.append(X_full[i:i+SEQ_LEN])\n",
    "    ys.append(y_full[i+SEQ_LEN])\n",
    "    tgt.append(i + SEQ_LEN)\n",
    "Xs, ys, tgt = np.array(Xs), np.array(ys), np.array(tgt)\n",
    "\n",
    "mask_test  = tgt >= cut                    # targets on/after the cutoff → test\n",
    "Xseq_tr, Yseq_tr = Xs[~mask_test], ys[~mask_test]\n",
    "Xseq_te, Yseq_te = Xs[mask_test], ys[mask_test]\n",
    "\n",
    "assert len(Yseq_te) == len(y_test), \"LSTM test size must match RF/XGB test size\"\n",
    "\n",
    "# 3) Normalize using TRAIN sequences only\n",
    "mu  = Xseq_tr.mean(axis=(0,1), keepdims=True)\n",
    "std = Xseq_tr.std(axis=(0,1),  keepdims=True); std[std==0] = 1e-6\n",
    "Xseq_tr = (Xseq_tr - mu)/std\n",
    "Xseq_te = (Xseq_te - mu)/std\n",
    "\n",
    "# 4) Tiny LSTM\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64, layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_features, hidden, num_layers=layers, batch_first=True, dropout=0.2)\n",
    "        self.fc   = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(-1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LSTMRegressor(n_features=Xseq_tr.shape[2]).to(device)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "lossf = nn.MSELoss()\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(Xseq_tr, dtype=torch.float32),\n",
    "                         torch.tensor(Yseq_tr, dtype=torch.float32))\n",
    "train_ld = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(6):  # quick fit\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_ld:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = lossf(pred, yb)\n",
    "        loss.backward(); opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: loss={epoch_loss/len(train_ld):.4f}\")\n",
    "\n",
    "# 5) Predict on SAME test span as RF/XGB\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_lstm = model(torch.tensor(Xseq_te, dtype=torch.float32, device=device)).cpu().numpy()\n",
    "\n",
    "# 6) Add to your existing comparison dict & re-plot (reuse your earlier block)\n",
    "models[\"LSTM (seq)\"] = (Yseq_te, y_pred_lstm)\n",
    "\n",
    "# Re-run the metrics + plotting cell you used for RF/XGB (no other changes needed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ============================================================\n",
    "# 1) Compute metrics safely\n",
    "# ============================================================\n",
    "eps = 1e-6\n",
    "mask = np.isfinite(y_test) & np.isfinite(y_pred)\n",
    "yt = np.asarray(y_test)[mask]\n",
    "yp = np.asarray(y_pred)[mask]\n",
    "\n",
    "errors = yp - yt\n",
    "abs_err = np.abs(errors)\n",
    "\n",
    "mae  = mean_absolute_error(yt, yp)\n",
    "rmse = mean_squared_error(yt, yp, squared=False)\n",
    "bias = float(np.mean(errors))\n",
    "smape = 100.0 * np.mean(2.0 * abs_err / (np.abs(yt) + np.abs(yp) + eps))\n",
    "pct_w5  = 100.0 * np.mean(abs_err <= 5)\n",
    "pct_w10 = 100.0 * np.mean(abs_err <= 10)\n",
    "\n",
    "# calibration fit\n",
    "coef = np.polyfit(yt, yp, deg=1) if yt.size > 1 else [0, 0]\n",
    "fit_fn = np.poly1d(coef)\n",
    "r2 = r2_score(yt, yp) if yt.size > 1 else 0.0\n",
    "\n",
    "# ============================================================\n",
    "# 2) Plotting\n",
    "# ============================================================\n",
    "plt.style.use(\"default\")\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "grid = fig.add_gridspec(3, 4, height_ratios=[0.6, 1.6, 1.6], hspace=0.8, wspace=0.8)\n",
    "\n",
    "# (A) Metric header table\n",
    "ax_head = fig.add_subplot(grid[0, :])\n",
    "ax_head.axis(\"off\")\n",
    "summary = pd.DataFrame([{\n",
    "    \"Model\": \"LSTM\",\n",
    "    \"MAE (min)\": f\"{mae:.2f}\",\n",
    "    \"RMSE (min)\": f\"{rmse:.2f}\",\n",
    "    \"Bias (min)\": f\"{bias:.2f}\",\n",
    "    \"sMAPE (%)\": f\"{smape:.1f}\",\n",
    "    \"≤5 min\": f\"{pct_w5:.1f}%\",\n",
    "    \"≤10 min\": f\"{pct_w10:.1f}%\"\n",
    "}])\n",
    "tbl = ax_head.table(cellText=summary.values, colLabels=summary.columns,\n",
    "                    cellLoc=\"center\", loc=\"center\")\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(11)\n",
    "ax_head.set_title(\"Accuracy Summary\", pad=12, fontsize=16, weight=\"bold\")\n",
    "\n",
    "# (B) Predicted vs Actual scatter\n",
    "ax_sc = fig.add_subplot(grid[1:, 0:2])\n",
    "if yt.size > 0:\n",
    "    ax_sc.scatter(yt, yp, s=15, alpha=0.5, edgecolors=\"none\")\n",
    "    mn, mx = float(np.min(yt)), float(np.max(yt))\n",
    "    ax_sc.plot([mn, mx], [mn, mx], \"r--\", lw=2, label=\"Ideal = Predicted\")\n",
    "    if yt.size > 5:\n",
    "        xx = np.linspace(mn, mx, 100)\n",
    "        ax_sc.plot(xx, fit_fn(xx), lw=2,\n",
    "                   label=f\"Fit: y={coef[0]:.2f}x+{coef[1]:.2f} (R²={r2:.2f})\")\n",
    "    ax_sc.set_xlabel(\"Actual RUL (minutes)\")\n",
    "    ax_sc.set_ylabel(\"Predicted RUL (minutes)\")\n",
    "    ax_sc.set_title(\"LSTM: Predicted vs Actual\")\n",
    "    ax_sc.grid(True, alpha=0.3)\n",
    "    ax_sc.legend(loc=\"upper left\")\n",
    "else:\n",
    "    ax_sc.text(0.5, 0.5, \"No valid test samples\", ha=\"center\", va=\"center\")\n",
    "    ax_sc.set_axis_off()\n",
    "\n",
    "# (C) Error histogram\n",
    "ax_err = fig.add_subplot(grid[1:, 2:])\n",
    "if errors.size > 0:\n",
    "    ax_err.hist(errors, bins=60, edgecolor=\"black\", alpha=0.7)\n",
    "    ax_err.axvline(0, color=\"k\", linestyle=\"--\", linewidth=1, label=\"Zero error\")\n",
    "    ax_err.axvline(errors.mean(), color=\"tab:red\", linestyle=\"--\", linewidth=2,\n",
    "                   label=f\"Mean bias = {errors.mean():.2f} min\")\n",
    "    ax_err.set_title(\"Prediction Error Distribution (Pred - Actual)\")\n",
    "    ax_err.set_xlabel(\"Error (minutes)\")\n",
    "    ax_err.set_ylabel(\"Count\")\n",
    "    ax_err.grid(True, alpha=0.3)\n",
    "    ax_err.legend()\n",
    "else:\n",
    "    ax_err.text(0.5, 0.5, \"No errors to display\", ha=\"center\", va=\"center\")\n",
    "    ax_err.set_axis_off()\n",
    "\n",
    "# (D) Epoch loss inset (if collected)\n",
    "if \"epoch_losses\" in globals() and len(epoch_losses) > 0:\n",
    "    inset = ax_sc.inset_axes([0.55, 0.05, 0.4, 0.35])\n",
    "    inset.plot(range(1, len(epoch_losses)+1), epoch_losses, marker=\"o\", ms=3)\n",
    "    inset.set_title(\"Epoch Loss\", fontsize=10)\n",
    "    inset.set_xlabel(\"Epoch\", fontsize=9)\n",
    "    inset.set_ylabel(\"MSE\", fontsize=9)\n",
    "    inset.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax_sc.text(0.02, 0.02, \"No epoch loss history recorded\",\n",
    "               transform=ax_sc.transAxes, fontsize=9, color=\"gray\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
